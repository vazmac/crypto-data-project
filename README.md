# ğŸš€ Crypto DataOps Pipeline: End-to-End Analytics Engineering

![DataOps](https://img.shields.io/badge/Methodology-DataOps-blue)
![Airflow](https://img.shields.io/badge/Orchestrator-Airflow_2.8.1-017CEE?logo=apacheairflow)
![dbt](https://img.shields.io/badge/Transformation-dbt_core-FF694B?logo=dbt)
![PostgreSQL](https://img.shields.io/badge/Database-PostgreSQL-4169E1?logo=postgresql)
![MinIO](https://img.shields.io/badge/Data_Lake-MinIO-C7202C?logo=minio)
![Docker](https://img.shields.io/badge/Infrastructure-Docker-2496ED?logo=docker)
![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub_Actions-2088FF?logo=githubactions)

## ğŸ“Œ VisÃ£o Geral do Projeto
Este projeto implementa uma arquitetura moderna de dados (Modern Data Stack) para extraÃ§Ã£o, transformaÃ§Ã£o e orquestraÃ§Ã£o de mÃ©tricas do mercado de criptomoedas (API CoinGecko). Desenhado com rigorosas prÃ¡ticas de **DataOps**, o pipeline foca-se em escalabilidade, reprodutibilidade, isolamento de recursos e CI/CD.

## ğŸ—ï¸ Arquitetura e Fluxo de Dados (ELT)

1. **ExtraÃ§Ã£o (Python + Airflow):** Scripts extraem dados da API e carregam-nos para a *Landing Zone* no Data Lake (MinIO) e para o schema `raw` no PostgreSQL.
2. **TransformaÃ§Ã£o (dbt):** - **Silver Layer (`staging`):** Limpeza, tipagem e normalizaÃ§Ã£o.
   - **Gold Layer (`marts`):** CriaÃ§Ã£o de tabelas de factos prontas para negÃ³cio, como `fct_daily_metrics`.
3. **DistribuiÃ§Ã£o:** GeraÃ§Ã£o de ficheiros `.csv` agregados e isolados num volume local (`/dashboard_data`) para consumo direto em ferramentas de BI (PowerBI/Tableau), garantindo que a camada de visualizaÃ§Ã£o nÃ£o sobrecarrega a base de dados transacional.

---

## ğŸ§  DecisÃµes de Arquitetura

Num cenÃ¡rio corporativo, as escolhas tecnolÃ³gicas devem equilibrar performance, custos e agilidade de desenvolvimento. Abaixo estÃ£o as justificaÃ§Ãµes para o design desta infraestrutura:

### 1. MinIO em vez de AWS S3 / GCP Cloud Storage
**O Desafio:** Desenvolver localmente com serviÃ§os Cloud reais gera custos desnecessÃ¡rios e requer gestÃ£o complexa de credenciais de IAM.
**A SoluÃ§Ã£o:** UtilizaÃ§Ã£o do MinIO via Docker. Sendo 100% compatÃ­vel com a API do Amazon S3, permite desenvolver e testar scripts de extraÃ§Ã£o em ambiente local (DEV). Quando o cÃ³digo transita para ProduÃ§Ã£o na Cloud, basta alterar as variÃ¡veis de ambiente, sem refatorizaÃ§Ã£o de cÃ³digo.

### 2. GitHub Actions em vez de Kubernetes (K8s) para SeparaÃ§Ã£o de Ambientes
**O Desafio:** Manter uma verdadeira separaÃ§Ã£o fÃ­sica entre DEV e PROD. Orquestrar isto localmente com K8s (Namespaces) exigiria recursos de hardware massivos (RAM/CPU), inviabilizando o desenvolvimento num computador pessoal.
**A SoluÃ§Ã£o:** Assumir o Docker local como um ambiente puro de Desenvolvimento (DEV). A garantia de qualidade Ã© feita atravÃ©s de **CI/CD com GitHub Actions**. A cada *Push*, o GitHub levanta um PostgreSQL efÃ©mero na cloud, instala o dbt, testa a compilaÃ§Ã£o do SQL (`dbt compile` e `dbt test`) e destrÃ³i o ambiente. Isto garante isolamento total de testes sem custos de infraestrutura permanente.

### 3. Desacoplamento do Apache Airflow (Scheduler vs. Webserver)
**O Desafio:** Correr todos os processos do Airflow num Ãºnico container (*monÃ³lito*) cria um *Single Point of Failure* (SPOF). Se a interface web consumir demasiada memÃ³ria, pode derrubar o motor de agendamento.
**A SoluÃ§Ã£o:** SeparaÃ§Ã£o do Airflow em dois microserviÃ§os no `docker-compose.yml`. O `airflow-scheduler` atua isoladamente como o motor crÃ­tico de orquestraÃ§Ã£o, enquanto o `airflow-webserver` gere apenas a UI. Isto permite escalabilidade independente e limita o *blast radius* em caso de falha.

### 4. GestÃ£o Rigorosa de DependÃªncias (Dependency Pinning)
**O Desafio:** O "Inferno de DependÃªncias" (Dependency Hell) no Python, onde pacotes atualizados silenciosamente quebram pipelines em ProduÃ§Ã£o.
**A SoluÃ§Ã£o:** FixaÃ§Ã£o estrita de versÃµes no `requirements.txt` (ex: `apache-airflow==2.8.1`), garantindo que os *builds* do Docker sÃ£o determinÃ­sticos e imunes a atualizaÃ§Ãµes indesejadas de pacotes terceiros (ex: providers da Amazon).

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```text
crypto_data_project/
â”œâ”€â”€ .github/workflows/      # Pipeline de CI/CD (simulaÃ§Ã£o de ambiente empresarial)
â”œâ”€â”€ dags/                   # DAGs do Airflow e scripts de extraÃ§Ã£o Python
â”‚   â”œâ”€â”€ market_data_extraction.py  # ExtraÃ§Ã£o de dados de mercado
â”‚   â”œâ”€â”€ serve_crypto.py             # ExtraÃ§Ã£o de dados maturados em formato CSV para enviar para a equipa responsÃ¡vel por PowerBI
â”‚   â”œâ”€â”€ watchlist_load.py          # Lista fixa de cryptomoedas a analisar
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ transform_crypto/       # Projeto dbt (TransformaÃ§Ã£o de Dados)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/        # Modelos da camada Silver
â”‚   â”‚   â””â”€â”€ marts/          # Modelos da camada Gold
â”‚   â”œâ”€â”€ macros/             # Macros Jinja personalizadas
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ seeds/
â”‚   â”œâ”€â”€ snapshots/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ scripts/                # Scripts de inicializaÃ§Ã£o com criaÃ§Ã£o de schema e tabelas raw necessÃ¡rias
â”‚   â””â”€â”€ init_db.sql
â”œâ”€â”€ plugins/                
â”œâ”€â”€ dashboard_data/         # Volume isolado de entrega de dados (Exports em CSV)
â”‚   â””â”€â”€ crypto_dashboard_2026-02-21.csv
â”œâ”€â”€ logs/                   # Logs dos DAGs executados
â”œâ”€â”€ docker-compose.yml      # Infraestrutura IaC (Postgres, PGAdmin, MinIO, Airflow)
â”œâ”€â”€ Dockerfile              # Imagem customizada de Airflow
â”œâ”€â”€ Makefile                # AutomaÃ§Ã£o de comandos do ciclo de vida local
â”œâ”€â”€ requirements.txt        # DependÃªncias de ambiente
â”œâ”€â”€ servers.json            # ConfiguraÃ§Ã£o de servidor e db no PGAdmin
â””â”€â”€ README.md               # DocumentaÃ§Ã£o do projeto